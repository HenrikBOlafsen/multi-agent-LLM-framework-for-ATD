from __future__ import annotations

from typing import Dict, Tuple, Optional

from agent_setup import AgentBase


REFACTORING_EXPERT_PROMPT = """Your job: Give useful context about a dependency cycle.

ATD rules:
- ANY reference counts (dynamic/lazy).
- Ignore type-only references (anything under TYPE_CHECKING).
- We care about static coupling, not just runtime import order.

Do not give a refactoring plan. Just give context about the cycle. Do not assess difficulty of breaking each edge. You are only to give facts, and never to make assumptions or suggestions. When unsure, say so.
Make your context as useful as possible.
Emphasize in your output that the reader should look at the actual code to see what will work best when trying to break the cycle.
"""


class RefactoringExpert(AgentBase):
    """
    Despite the name, this agent is used as a *cycle context summarizer*.
    We keep the class name because orchestrators call it, but prompt variants control behavior.

    prompt_variant:
      - "default": uses DEFAULT_REFACTORING_EXPERT_PROMPT
      - any other string: treated as a custom prompt (you can pass a full prompt)
    """

    def __init__(self, name: str, client, prompt_variant: str = "default", prompt_text: Optional[str] = None):
        if prompt_text is not None:
            system_prompt = prompt_text
        elif prompt_variant == "default":
            system_prompt = DEFAULT_REFACTORING_EXPERT_PROMPT
        else:
            # If you want to manage variants elsewhere, pass prompt_text explicitly.
            # Keeping this strict avoids hidden/legacy behavior.
            system_prompt = prompt_variant

        super().__init__(name, client, system_prompt)

    def propose(
        self,
        dep_summaries_A: Dict[str, Tuple[str, str]],
        dep_summaries_B: Dict[str, Tuple[str, str]],
        cycle_explanation: str,
    ) -> str:
        """
        dep_summaries_A: {A_path: (B_path, summary_text)}
        dep_summaries_B: {A_path: (B_path, summary_text)}  # "parts of B used by A"
        cycle_explanation: string from CycleExpert (may contain flaws)

        Returns:
          Plain text response from the LLM (no wrapper tags here).
        """
        self.reset()

        # Keep deterministic ordering: rely on dict insertion order (Python 3.7+).
        A_deps_text = "\n\n".join(
            f"Edge {i+1}: {a} → {b}\n{txt}"
            for i, (a, (b, txt)) in enumerate(dep_summaries_A.items())
        )

        B_deps_text = "\n\n".join(
            f"Edge {i+1}: {a} → {b}\n{txt}"
            for i, (a, (b, txt)) in enumerate(dep_summaries_B.items())
        )

        user = f"""Here is the data:

Context (edges A->B with summaries):
{A_deps_text}

Additional detail (what parts of B are used by A):
{B_deps_text}

Cycle explanation (generated by another LLM. Might include flaws, so be sceptical):
{cycle_explanation}
"""

        return self.ask(user)

    def propose_two_stage(self, merged_edges: Dict[str, Dict[str, str]], cycle_nodes: list[str]) -> str:
        """
        Optional helper for orchestrators that produce a merged per-edge structure.

        merged_edges example:
          {
            "a.py -> b.py": {"a_path": "...", "b_path": "...", "why": "...", "used": "..."},
            ...
          }
        """
        self.reset()

        edges_text_parts = []
        for i, (k, v) in enumerate(merged_edges.items(), 1):
            a_path = v.get("a_path", "")
            b_path = v.get("b_path", "")
            why = v.get("why", "")
            used = v.get("used", "")
            edges_text_parts.append(
                f"Edge {i}: {a_path} → {b_path}\n"
                f"- Why A depends on B:\n{why}\n\n"
                f"- What in B is used by A:\n{used}"
            )

        edges_text = "\n\n".join(edges_text_parts)
        cycle_text = " -> ".join([*cycle_nodes, cycle_nodes[0]]) if cycle_nodes else "N/A"

        user = f"""Here is the data:

Cycle (node chain):
{cycle_text}

Merged per-edge summaries:
{edges_text}
"""
        return self.ask(user)
